# RAG-ing Modular PoC Configuration
# Aligned with Requirement.md specification

# Module 1: Corpus & Embedding Lifecycle Configuration
data_source:
  type: "local_file"  # confluence | local_file
  path: "./data/"
  confluence:
    base_url: "https://your-domain.atlassian.net/wiki"
    auth_token: "${CONFLUENCE_TOKEN}"
    space_key: "ONCOLOGY"
    page_filter: ["biomarkers", "protocols"]

chunking:
  strategy: "recursive"  # recursive | semantic
  chunk_size: 512
  overlap: 64

embedding_model:
  name: "pubmedbert"
  device: "cpu"

# Module 2: Query Processing & Retrieval Configuration  
retrieval:
  top_k: 5
  strategy: "similarity"  # similarity | hybrid
  filters:
    ontology_match: true
    date_range: "last_12_months"

# Module 3: LLM Orchestration Configuration
llm:
  model: "gpt-5-nano"  # For Azure OpenAI, use your deployment name
  provider: "azure_openai"  # Options: koboldcpp, openai, azure_openai, anthropic
  api_url: "http://localhost:5000/v1"  # Only used for koboldcpp
  prompt_template: "./prompts/oncology.txt"
  system_instruction: "You are a biomedical assistant specializing in oncology. Provide evidence-based responses with proper citations."
  temperature: 1.0  # gpt-5-nano requires default temperature
  max_tokens: 1000  # Increased for gpt-5-nano reasoning tokens

# Module 4: UI Layer Configuration
ui:
  framework: "streamlit"
  audience_toggle: true
  feedback_enabled: true
  show_chunk_metadata: true
  default_model: "biomistral"
  default_source: "confluence"

# Module 5: Evaluation & Logging Configuration
evaluation:
  metrics:
    precision_at_k: true
    citation_coverage: true
    clarity_rating: true
    latency: true
    safety: true
  logging:
    enabled: true
    format: "json"
    path: "./logs/"

# Vector Store Configuration
vector_store:
  type: "chroma"
  path: "./vector_store"
  collection_name: "oncology_docs"