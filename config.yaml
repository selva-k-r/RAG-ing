# RAG-ing Modular PoC Configuration
# This YAML file configures all 5 modules of the oncology-focused RAG system

# Data Sources Configuration
data_sources:
  - path: "./data"
    type: "directory"
    file_patterns: ["*.pdf", "*.txt", "*.md"]
    recursive: true
    metadata:
      domain: "oncology"
      source_type: "research_docs"
  
  - path: "./pubmed_abstracts"  # Example path for PubMed data
    type: "directory" 
    file_patterns: ["*.xml", "*.json"]
    recursive: false
    metadata:
      domain: "biomedical"
      source_type: "pubmed"
      
  - path: "${CLINICAL_DOCS_PATH}"  # Environment variable example
    type: "directory"
    file_patterns: ["*.pdf"]
    recursive: true
    metadata:
      domain: "clinical"
      source_type: "clinical_trials"
      requires_auth: true

# Chunking Strategy Configuration  
chunking:
  strategy: "semantic"  # Options: semantic, fixed_size, recursive
  chunk_size: 1000      # Token count for fixed_size
  chunk_overlap: 200    # Overlap between chunks
  min_chunk_size: 100   # Minimum viable chunk size
  
  # Semantic chunking parameters
  semantic:
    similarity_threshold: 0.8
    sentence_splitter: "spacy"  # Options: spacy, nltk, custom
    
  # Ontology-aware chunking for medical documents
  ontology:
    extract_codes: true
    code_systems: ["ICD-O", "SNOMED-CT", "UMLS"]
    preserve_context: true

# Embedding Model Configuration
# Modular RAG PoC Configuration
# This YAML file configures all 5 modules of the Oncology-focused RAG system

# Module 1: Corpus & Embedding Lifecycle Configuration
data_sources:
  - path: "./data/sample.pdf"
    type: "pdf"
    enabled: true
    metadata:
      domain: "oncology"
      source_type: "research_paper"
      
  - path: "./data/sample.txt"
    type: "text"
    enabled: true
    metadata:
      domain: "oncology"
      source_type: "clinical_notes"

  - path: "./data/"
    type: "directory"
    enabled: true
    file_patterns: ["*.md", "*.txt", "*.pdf"]
    exclude_patterns: ["**/.*", "**/__pycache__/**"]
    metadata:
      domain: "oncology"

chunking:
  chunk_size: 1000
  chunk_overlap: 200
  chunking_strategy: "semantic"  # Options: semantic, fixed, sentence, paragraph
  min_chunk_size: 100
  max_chunk_size: 2000
  respect_sentence_boundaries: true
  
  # Ontology-specific chunking for medical domain
  ontology_extraction:
    enabled: true
    ontology_types: ["ICD-O", "SNOMED-CT", "MeSH"]
    preserve_ontology_context: true

embedding_model:
  # Biomedical models for oncology domain
  model_name: "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext"
  fallback_model: "sentence-transformers/all-MiniLM-L6-v2"
  model_type: "huggingface"  # Options: huggingface, openai, local
  batch_size: 32
  max_seq_length: 512
  device: "auto"  # auto, cpu, cuda
  cache_dir: "./models/cache"

vector_store:
  provider: "chroma"  # Options: chroma, faiss, pinecone
  collection_name: "oncology_rag_collection"
  persist_directory: "./data/chroma_db"
  distance_metric: "cosine"  # cosine, euclidean, dot_product
  
  # ChromaDB specific settings
  chroma_settings:
    anonymized_telemetry: false
    allow_reset: true
    
  # Index optimization
  index_settings:
    enable_hnsw: true
    hnsw_m: 16
    hnsw_ef_construction: 200

# Module 2: Query Processing & Retrieval Configuration
retrieval:
  top_k: 5
  similarity_threshold: 0.7
  max_tokens_per_chunk: 1000
  
  # Multi-stage retrieval
  retrieval_strategy: "hybrid"  # Options: semantic, keyword, hybrid
  keyword_weight: 0.3
  semantic_weight: 0.7
  
  # Query enhancement
  query_expansion:
    enabled: true
    expansion_method: "synonyms"  # Options: synonyms, embeddings, llm
    max_expansions: 3
    
  # Filtering and reranking
  filters:
    domain_filter: "oncology"
    min_relevance_score: 0.5
    
  reranking:
    enabled: true
    rerank_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    rerank_top_k: 10
    
  # Caching for performance
  cache:
    enabled: true
    cache_type: "memory"  # memory, redis, file
    cache_ttl: 3600  # seconds
    max_cache_size: 1000

# Module 3: LLM Orchestration Configuration
llm:
  # Primary LLM configuration (KoboldCpp for local deployment)
  primary_model:
    provider: "koboldcpp"
    model_name: "local-clinical-llm"
    base_url: "http://localhost:5001"
    api_key: "${KOBOLD_API_KEY}"  # Environment variable
    max_tokens: 2048
    temperature: 0.3
    top_p: 0.9
    presence_penalty: 0.1
    frequency_penalty: 0.1
    
  # Fallback models
  fallback_models:
    - provider: "openai"
      model_name: "gpt-3.5-turbo"
      api_key: "${OPENAI_API_KEY}"
      max_tokens: 2048
      temperature: 0.3
      
    - provider: "anthropic"
      model_name: "claude-3-haiku-20240307"
      api_key: "${ANTHROPIC_API_KEY}"
      max_tokens: 2048
      temperature: 0.3
  
  # Prompt configuration
  prompts:
    system_prompt: |
      You are an expert oncology AI assistant. Provide accurate, evidence-based information 
      about cancer research, treatment options, and clinical guidelines. Always cite your sources 
      and include appropriate medical disclaimers. Focus on being helpful while maintaining 
      clinical accuracy.
      
    clinical_prompt_template: |
      Based on the following oncology literature and clinical data:
      
      {context}
      
      Please answer the following clinical question: {query}
      
      Provide a comprehensive response that includes:
      1. Direct answer to the question
      2. Supporting evidence from the provided sources
      3. Clinical considerations and limitations
      4. Relevant citations
      
      Remember to include appropriate medical disclaimers.
      
    technical_prompt_template: |
      Using the following research documents and technical information:
      
      {context}
      
      Answer this research question: {query}
      
      Provide a detailed technical response including:
      1. Methodology and findings
      2. Statistical significance and confidence intervals
      3. Study limitations and bias considerations
      4. References to source materials
  
  # Response configuration
  generation:
    max_retries: 3
    retry_delay: 1.0
    timeout: 30.0
    stream_response: true
    include_citations: true
    citation_format: "numbered"  # numbered, inline, footnote

# Module 4: UI Layer Configuration
ui:
  # Interface settings
  title: "Oncology RAG Assistant"
  description: "AI-powered oncology research and clinical decision support"
  theme: "clinical"  # clinical, research, default
  
  # Audience toggle feature
  audience_toggle:
    enabled: true
    default_audience: "clinical"  # clinical, technical
    
    clinical_features:
      - "simplified_language"
      - "clinical_guidelines"
      - "treatment_recommendations"
      - "safety_warnings"
      
    technical_features:
      - "detailed_methodology"
      - "statistical_analysis" 
      - "research_limitations"
      - "peer_review_status"
  
  # Feedback collection
  feedback:
    enabled: true
    feedback_types: ["clarity", "citation", "safety", "usefulness"]
    rating_scale: 5
    collect_comments: true
    anonymous_mode: true
    
  # Interface customization
  layout:
    sidebar_width: 300
    main_width: 700
    show_source_documents: true
    show_confidence_scores: true
    show_processing_time: true
    
  # Query interface
  query_interface:
    placeholder_text: "Ask a question about oncology research or clinical guidelines..."
    max_query_length: 500
    query_suggestions: true
    query_history: true
    max_history_items: 20

# Module 5: Evaluation & Logging Configuration
evaluation:
  # Metrics to track
  metrics:
    precision_at_k: true
    citation_coverage: true
    clarity_rating: true
    safety: true
    latency: true
    
  # Logging configuration
  logging:
    enabled: true
    level: "INFO"  # DEBUG, INFO, WARNING, ERROR
    path: "./logs/"
    
    # Structured logging
    format: "json"
    include_metadata: true
    log_queries: true
    log_responses: true
    log_user_feedback: true
    
    # Log rotation
    max_file_size: "100MB"
    backup_count: 5
    
  # Performance monitoring
  monitoring:
    track_response_time: true
    track_memory_usage: true
    track_error_rates: true
    alert_thresholds:
      max_response_time: 30.0  # seconds
      max_error_rate: 0.1  # 10%
      
  # Data privacy
  privacy:
    anonymize_queries: false  # Set to true for production
    anonymize_feedback: true
    data_retention_days: 90

# Global Configuration
global:
  # Environment settings
  environment: "development"  # development, staging, production
  debug_mode: true
  log_level: "INFO"
  
  # API rate limiting
  rate_limiting:
    enabled: false
    requests_per_minute: 60
    
  # Security settings
  security:
    enable_cors: true
    allowed_origins: ["http://localhost:3000", "http://127.0.0.1:3000"]
    api_key_required: false
    
  # Performance settings
  performance:
    enable_caching: true
    cache_timeout: 3600
    max_concurrent_requests: 10
    
  # Data paths (can use environment variables)
  paths:
    data_dir: "${DATA_DIR:./data}"
    models_dir: "${MODELS_DIR:./models}"
    logs_dir: "${LOGS_DIR:./logs}"
    cache_dir: "${CACHE_DIR:./cache}"

# Vector Store Configuration
vector_store:
  provider: "chroma"  # Options: chroma, faiss, pinecone
  
  # ChromaDB configuration
  chroma:
    persist_directory: "./chroma_db"
    collection_name: "oncology_docs"
    distance_metric: "cosine"  # Options: cosine, l2, ip
    
  # FAISS configuration (alternative)
  faiss:
    index_type: "IndexFlatIP"  # Options: IndexFlatL2, IndexFlatIP, IndexIVFFlat
    index_path: "./faiss_index"
    
  # Indexing parameters
  embedding_dimension: 768  # PubMedBERT dimension
  batch_size: 1000

# Retrieval Configuration
retrieval:
  # Search parameters
  similarity_search:
    k: 5  # Number of documents to retrieve
    similarity_threshold: 0.7
    
  # Filtering options
  filters:
    enable_metadata_filtering: true
    enable_date_filtering: false
    enable_domain_filtering: true
    
  # Re-ranking configuration
  reranking:
    enabled: true
    model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    top_k: 10  # Documents to re-rank
    final_k: 5  # Final documents after re-ranking
    
  # Caching for performance
  caching:
    enabled: true
    cache_size: 1000
    ttl_seconds: 3600  # 1 hour

# LLM Configuration
llm:
  # Primary LLM provider
  provider: "koboldcpp"  # Options: koboldcpp, openai, anthropic, ollama
  
  # KoboldCpp configuration for local deployment
  koboldcpp:
    base_url: "${KOBOLD_URL:-http://localhost:5001}"
    model_name: "medical-llama-7b"  # Example medical model
    api_key: "${KOBOLD_API_KEY}"
    
    # Generation parameters
    generation:
      max_tokens: 2048
      temperature: 0.3  # Lower for factual medical content
      top_p: 0.9
      frequency_penalty: 0.0
      presence_penalty: 0.0
      
  # OpenAI configuration (alternative)
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4"
    base_url: null  # Use default
    
  # Anthropic configuration (alternative)  
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    model: "claude-3-sonnet-20240229"
    
  # Prompt templates
  prompts:
    # Clinical audience prompt
    clinical_template: |
      You are a clinical decision support system specialized in oncology. 
      Based on the following medical literature and guidelines:
      
      {context}
      
      Question: {query}
      
      Provide a comprehensive response that:
      1. Directly addresses the clinical question
      2. Cites relevant sources with specific page numbers when available
      3. Includes appropriate medical disclaimers
      4. Suggests further consultation when appropriate
      
      Remember: This information is for clinical reference only and should be used in conjunction with clinical judgment.
      
    # Technical audience prompt  
    technical_template: |
      You are a biomedical research assistant with expertise in oncology research.
      Based on the following research literature:
      
      {context}
      
      Research Question: {query}
      
      Provide a detailed technical response that:
      1. Synthesizes findings from the literature
      2. Identifies key methodologies and results
      3. Cites sources with DOI/PMID when available
      4. Highlights limitations and future research directions
      5. Uses appropriate scientific terminology
      
  # Response configuration
  response:
    max_context_length: 8000  # Max tokens for context
    citation_style: "numerical"  # Options: numerical, author_year, inline
    include_confidence: true
    medical_disclaimer: true

# UI Configuration
ui:
  # Interface settings
  interface:
    title: "Oncology RAG Assistant"
    sidebar_width: 300
    theme: "light"  # Options: light, dark, auto
    
  # Audience toggle
  audience_toggle:
    enabled: true
    default: "clinical"  # Options: clinical, technical
    
    audiences:
      clinical:
        label: "Clinical Practice"
        description: "Optimized for healthcare providers and clinical decision-making"
        prompt_key: "clinical_template"
        
      technical:
        label: "Research & Development" 
        description: "Optimized for researchers and technical analysis"
        prompt_key: "technical_template"
        
  # Feedback collection
  feedback:
    enabled: true
    ratings:
      - name: "clarity"
        label: "Clarity"
        scale: 5
        required: false
        
      - name: "citation"
        label: "Citation Quality"
        scale: 5
        required: false
        
      - name: "safety"
        label: "Safety & Disclaimers"
        scale: 5
        required: true
        
      - name: "usefulness"
        label: "Clinical Usefulness"
        scale: 5
        required: false
        
    # Feedback storage
    storage:
      enabled: true
      path: "./feedback.jsonl"
      
  # Query history
  history:
    enabled: true
    max_queries: 100
    persist: true
    path: "./query_history.json"

# Evaluation & Logging Configuration
evaluation:
  # Metrics to track
  metrics:
    precision_at_k: true     # Retrieval precision
    citation_coverage: true  # How well responses cite sources
    clarity_rating: true     # User feedback on clarity
    safety: true            # Medical safety compliance
    latency: true           # Response time tracking
    
  # Logging configuration  
  logging:
    enabled: true
    path: "./logs/"
    level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR
    
    # Structured logging formats
    formats:
      query_events: "jsonl"      # One JSON object per line
      metrics: "jsonl" 
      errors: "json"
      
    # Log rotation
    rotation:
      enabled: true
      max_size_mb: 100
      backup_count: 5
      
  # Performance tracking
  performance:
    track_system_metrics: true
    memory_monitoring: true
    error_tracking: true
    
  # Privacy and compliance
  privacy:
    anonymize_queries: false  # Set true for production
    retain_days: 90          # Data retention period
    gdpr_compliant: true

# Environment and Infrastructure
environment:
  # Resource limits
  resources:
    max_memory_gb: 8
    max_cpu_percent: 80
    gpu_memory_fraction: 0.8
    
  # Cache configuration
  cache:
    enabled: true
    type: "memory"  # Options: memory, redis, disk
    size_mb: 512
    
  # Security settings
  security:
    enable_auth: false  # Set true for production
    allowed_origins: ["*"]
    api_rate_limit: 100  # Requests per minute
    
# Development and Testing
development:
  debug_mode: false
  log_level: "INFO"
  reload_on_change: false
  
  # Testing configuration
  testing:
    sample_queries: [
      "What are the latest treatments for pancreatic cancer?",
      "Explain the mechanism of action for PD-1 inhibitors in oncology",
      "What are the side effects of CAR-T cell therapy?"
    ]
    
    test_datasets: [
      "./test_data/medical_qa.json",
      "./test_data/oncology_guidelines.pdf"
    ]